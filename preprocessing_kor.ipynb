{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.lib import tokenizing_without_stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from soynlp import DoublespaceLineCorpus\n",
    "from soynlp.word import WordExtractor\n",
    "from soynlp.tokenizer import LTokenizer\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = DoublespaceLineCorpus(\"./data/2016-10-20.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.740 Gb\n",
      "all cohesion probabilities was computed. # words = 223348\n",
      "all branching entropies was computed # words = 361598\n",
      "all accessor variety was computed # words = 361598\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(corpus)\n",
    "word_score_table = word_extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "train = pd.read_csv('./data/processed/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {word:score.cohesion_forward for word, score in word_score_table.items()}\n",
    "l_tokenizer = LTokenizer(scores=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:,'document'] = train['document'].apply(lambda x:tokenizing_without_stopwords(x,l_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    [더빙, 진짜, 짜증, 나네요, 목소리]\n",
       "1                           [흠포스터보고, 초딩영화줄오버연기조차, 가볍지, 않구나]\n",
       "2                                     [너무, 재밓었다그래서보는것을추천한다]\n",
       "3                    [교도소, 이야기, 구먼, 솔직, 히, 재미는, 없다, 평점, 조정]\n",
       "4         [사이몬페그의, 익살스, 런, 연기, 돋보, 였던, 영화, 스파이더맨에서, 늙어, ...\n",
       "                                ...                        \n",
       "148735                               [인간이, 문제, 지, 소는, 뭔죄인가]\n",
       "148736                                     [평점이, 너무, 낮아, 서]\n",
       "148737              [이게, 뭐요, 한국, 인은, 거들먹거리고, 필리핀, 혼혈은, 착하다]\n",
       "148738                   [청춘, 영화, 최고, 봉방황과, 우울했던, 날들의, 자화상]\n",
       "148739                     [한국, 영화, 최초로, 수간하는, 내용이, 담긴, 영화]\n",
       "Name: document, Length: 148740, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4fe7a65e16781ebce1fdb8c74096656eac6964dbb1774f4c65d543e2bcc2ead"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
